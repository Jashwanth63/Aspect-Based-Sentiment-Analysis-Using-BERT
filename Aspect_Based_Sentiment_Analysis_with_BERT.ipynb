{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jashwanth63/Aspect-Based-Sentiment-Analysis-Using-BERT/blob/main/Aspect_Based_Sentiment_Analysis_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWgujXmGqzIC"
      },
      "source": [
        "# Lab 8 - Aspect-Based Sentiment Analysis with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr5PWYKGPi6R"
      },
      "source": [
        "In this lab we turn a pre-trained BERT model into a trainable Keras layer and apply it to the Aspect-Based Sentiment Analysis that we tackled in lab 4. BERT (Bidirectional Embedding Representations from Transformers) is a new model for pre-training language representations that obtains state-of-the-art results on many NLP tasks. We demonstrate how to integrate BERT as a custom Keras layer to simplify model prototyping using huggingface. In this lab, you will learn: \n",
        "\n",
        "1) How to use the huggingface package.\n",
        "\n",
        "2) How to integrate BERT in our previous model. \n",
        "\n",
        "3) How to use the TPU from Colab. (Note: Running BERT on the CPU would be very slow. Thus we recommend you to do this lab on Colab based on TPU provided by Google.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4spJ5PRhGJ1l"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oimYsLssuSs"
      },
      "source": [
        "Before start, we should install the huggingface transformer package. You can find the doc from its [website](https://huggingface.co/transformers/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AElpzsKFiZSo",
        "outputId": "ce44d96d-aa29-4c19-ae9a-dbe5f57f4ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebbamBD0xu5z"
      },
      "source": [
        "## Preprocessing and Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAMXQwqyVT8"
      },
      "source": [
        "In this lab we will use DistilBERT instead of BERT: DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, and runs 60% faster, while preserving over 95% of BERT’s performance as measured on the GLUE language understanding benchmark.\n",
        "\n",
        "It is easy to switch between DistilBERT and BERT using the huggingface transformer package. This huggingface package provides many pre-trained and pre-built models that are easy to use via a few lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-cUTxt02dQb"
      },
      "source": [
        "Before using DistilBERT or BERT, we need a tokenizer. Generally speaking, every BERT related model has its own tokenizer, trained for that model (see this week's lecture video on sub-word tokenization). \n",
        "We can get the DistilBERT tokenizer from **DistilBertTokenizer.from_pretrained** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "603b444594044c13bcd95e4326932916",
            "a45d989bad384e6bb09d3fd648485481",
            "8996286e91b446acba5d31753a2121e1",
            "020814c33aa34187ac9f46631204b3ad",
            "e43c6551c5264decb678dec78d47ca89",
            "e44e3ca7ef4f40699035d53c2230650b",
            "b8ec4135f891402d9e855025de7fd139",
            "c8fcf93d4a154c2faac2e61d974bcd8b",
            "26e88d50bcdd44b9948dbf2b26fd5619",
            "34751423926b4d5a92a987fb7b66d825",
            "076763a9cf6f437faa1eed7fae368ef2",
            "63d4af1040644f8ab868bc4e1ebb824b",
            "5d599a08bba348ffa3713281329c5ecc",
            "eab4d125e4d645cc8794fef7d9c729df",
            "e679624f746143458f9aa8cd8fa9ae8c",
            "5d3b0b66524c4c11a6df09ea04839d6a",
            "96b7a50632b74a7e8de6f46adb99fc54",
            "c649cec29f5c466895fda131bcfe2066",
            "2897a4b6f0e14ce491a8eeba3aec35d9",
            "5c6499375ece40b4b242cf29721338b8",
            "381f195ac3d14e3da41361f694ce6576",
            "2b7a19a3230f4b039c7e60aad832d24d",
            "8a945c9b3275464383694131671471cd",
            "626c275f65fc473d9c39972fb75f8430",
            "b5fdbe67f0954c15acb312306da61f26",
            "253bdcf2debc46eea9b8c339e3a06159",
            "cb270f10aa204daeb1846861ac7ae97e",
            "f436b1ec37cf47fcaa99a3aad033a003",
            "540df8063f0b431da5558a3772fa8066",
            "0d9ddcf3406147b7a2d69e7327f0e461",
            "6f194fd3087e4ac5bbf0333de3497e46",
            "8c2e5d4f6a8849068636a367a481d84b",
            "19bae60aec6d4189b9c5c01787d83b21"
          ],
          "height": 113
        },
        "id": "hKj6Y_TydjeS",
        "outputId": "9858243f-e506-4d64-9b6d-d6a02d6cf159"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "603b444594044c13bcd95e4326932916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63d4af1040644f8ab868bc4e1ebb824b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a945c9b3275464383694131671471cd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, RobertaTokenizer \n",
        "import tqdm\n",
        "distil_bert = 'distilbert-base-uncased' # Pick any desired pre-trained model\n",
        "\n",
        "# Defining DistilBERT tokonizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n",
        "                                                max_length=128, pad_to_max_length=True)\n",
        "\n",
        "def tokenize(sentences, tokenizer, pad_length=128, pad_to_max_length=True ):\n",
        "    if type(sentences) == str:\n",
        "        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqMo6CPS3qJZ"
      },
      "source": [
        "Then we can use the tokenizer to tokenize the sentence. When working with word2vec and GloVe, we tokenized the sentence into words ourselves and then converted the tokens to GloVe word indices. But in BERT, we must use the BERT tokenizer: the tokens for BERT are different, and include whole words and sub-word tokens (see lecture video on sub-word tokenisation).\n",
        "\n",
        "For example, for the sentence: **This is a pretrained model.** our previous word-based tokenizer will generate the following tokens:\n",
        "\n",
        "**\"this\", \"is\", \"a\", \"pretrained\", \"model\", \".\"**\n",
        "\n",
        "Then you will find out that the word token \"pretrained\" is not in the GloVe word dictionary. Thus we can not assign a proper word vector for \"pretrained\".\n",
        "\n",
        "In BERT, the BERT tokenizer will separate the word \"pretrained\" into three sub-word tokens:\n",
        "\n",
        "**'pre', '##train', '##ed'**\n",
        "\n",
        "This way, BERT can use these three token vectors to represent the word \"pretrained\". Without the BERT tokenizer, it is hard to separate these unknown words properly.\n",
        "\n",
        "You will also see that the BERT tokenizer adds the special sentence [CLS] token and sentence separator [SEP] tokens (see this week's lecture videos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRoKe2DKyi41",
        "outputId": "d50a55d7-6cb9-43e4-a60c-a7b1d412bf8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'capital', 'of', 'france', 'is', '[MASK]', '.'] \n",
            "\n",
            "['this', 'is', 'a', 'pre', '##train', '##ed', 'model', '.'] \n",
            "\n",
            "[ 101 1996 3007 1997 2605 2003  103 1012  102    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
            "\n",
            "[ 101 1996 3007 1997 2605 2003  103 1012  102]\n",
            "[1 1 1 1 1 1 1 1 1]\n",
            "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]'] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n",
        "print(inputs,'\\n')\n",
        "\n",
        "inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n",
        "print(inputs,'\\n')\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n",
        "print(ids)\n",
        "print(masks)\n",
        "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n",
        "print(ids)\n",
        "print(masks)\n",
        "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids,masks,segments = tokenize(\"This is a pretrained model.\", tokenizer, pad_to_max_length=False)\n",
        "print(ids)\n",
        "print(masks)\n",
        "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL662yD2-vwU",
        "outputId": "9b9aaea2-7f0c-4c43-9262-21889fee1419"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101  2023  2003  1037  3653 23654  2098  2944  1012   102]\n",
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "['[CLS]', 'this', 'is', 'a', 'pre', '##train', '##ed', 'model', '.', '[SEP]'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6OuZAA8sbdg"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqvPQvgvPv1W"
      },
      "source": [
        "### Downloading and preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EundMtGPpCdf"
      },
      "source": [
        "Similar to lab 4, we need to download and preprocess the data first. The data download code is consistent with lab 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyuSzkafqNca",
        "outputId": "29153ab9-2f04-4896-f6b1-2c3122773dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 11186\n",
            "Test entries: 1336\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "def downloadfile(url):\n",
        "  rq = requests.get(url)\n",
        "  open(url.split('/')[-1], 'wb').write(rq.content)\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/train.xml')\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/val.xml')\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/test.xml')\n",
        "\n",
        "\n",
        "# The code is modified from https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data_process/utils.py\n",
        "from xml.etree.ElementTree import parse\n",
        "\n",
        "def parse_sentence_term(path, lowercase=False):\n",
        "    tree = parse(path)\n",
        "    sentences = tree.getroot()\n",
        "    data = []\n",
        "    split_char = '__split__'\n",
        "    for sentence in sentences:\n",
        "        text = sentence.find('text')\n",
        "        if text is None:\n",
        "            continue\n",
        "        text = text.text\n",
        "        if lowercase:\n",
        "            text = text.lower()\n",
        "        aspectTerms = sentence.find('aspectTerms')\n",
        "        if aspectTerms is None:\n",
        "            continue\n",
        "        for aspectTerm in aspectTerms:\n",
        "            term = aspectTerm.get('term')\n",
        "            if lowercase:\n",
        "                term = term.lower()\n",
        "            polarity = aspectTerm.get('polarity')\n",
        "            start = aspectTerm.get('from')\n",
        "            end = aspectTerm.get('to')\n",
        "            piece = [text , term,  polarity , start , end]\n",
        "            data.append(piece)\n",
        "    return data\n",
        "train = parse_sentence_term(\"train.xml\",True)\n",
        "dev = parse_sentence_term(\"val.xml\",True)\n",
        "test = parse_sentence_term(\"test.xml\",True)\n",
        "\n",
        "print(\"Training entries: {}\".format(len(train)))\n",
        "print(\"Test entries: {}\".format(len(test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4iCV9-rmay"
      },
      "source": [
        "We now can start playing around with the data, let’s first see some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-gjWRAuqg5s",
        "outputId": "9da911ef-f332-4757-807f-705ebded5b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE \t ASPECT \t LABLE \t ASPECT-START-INDEX \t ASPECT-END-INDEX\n",
            "['the decor is not special at all but their food and amazing prices make up for it.', 'decor', 'negative', '4', '9']\n",
            "['the decor is not special at all but their food and amazing prices make up for it.', 'food', 'positive', '42', '46']\n",
            "['the decor is not special at all but their food and amazing prices make up for it.', 'prices', 'positive', '59', '65']\n",
            "['when tables opened up, the manager sat another party before us.', 'tables', 'neutral', '5', '11']\n",
            "['when tables opened up, the manager sat another party before us.', 'manager', 'negative', '27', '34']\n",
            "['after a couple of drinks, the apps--i like the lobster/mango summer roll and the cripsy squid--go down great.', 'drinks', 'neutral', '18', '24']\n"
          ]
        }
      ],
      "source": [
        "print(\"SENTENCE \\t ASPECT \\t LABLE \\t ASPECT-START-INDEX \\t ASPECT-END-INDEX\")\n",
        "print(train[0])\n",
        "print(train[1])\n",
        "print(train[2])\n",
        "print(train[3])\n",
        "print(train[4])\n",
        "print(dev[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvuu4KhStqei"
      },
      "source": [
        "According to the BERT tokenize function above, we can convert the tweet text and topic words to integers:\n",
        "\n",
        "(Note: the BERT tokenize function is different from lab 4.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids,masks,segments = tokenize(\"decor\", tokenizer, pad_to_max_length=False)\n",
        "print(ids)\n",
        "print(tokenizer.convert_ids_to_tokens(101\n",
        "                                      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9sCcyel_Ro0",
        "outputId": "9b1ee156-8cd4-4a41-c1b5-9a834c65b3ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101 25545   102]\n",
            "[CLS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMCH1OoDrSNR",
        "outputId": "8b207c06-17d6-4818-ee40-14bab08d987a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_dev_aspect_int[0]:\n",
            "[ 101 8974  102]\n",
            "x_dev_aspect_masks[0]:\n",
            "[1 1 1]\n",
            "x_dev_review_int[0]:\n",
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102]\n",
            "x_dev_review_masks[0]:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# Please write your code to generate the following data\n",
        "# x_train_review_int\n",
        "# x_train_review_masks\n",
        "# x_train_aspect_int\n",
        "# x_train_aspect_masks\n",
        "\n",
        "# x_dev_review_int\n",
        "# x_dev_review_masks\n",
        "# x_dev_aspect_int\n",
        "# x_dev_aspect_masks\n",
        "\n",
        "# x_test_review_int\n",
        "# x_test_review_masks\n",
        "# x_test_aspect_int\n",
        "# x_test_aspect_masks\n",
        "def id_aspect(data, index):\n",
        "  data_id = []\n",
        "  mask_id = []\n",
        "  for sentence in data:\n",
        "    id, masks, segments = tokenize(sentence[index], tokenizer, pad_to_max_length=False)\n",
        "    data_id.append(id)\n",
        "    mask_id.append(masks)\n",
        "  return data_id, mask_id\n",
        "\n",
        "#Validation Data\n",
        "x_dev_review_int = []\n",
        "x_dev_review_masks = []\n",
        "\n",
        "x_dev_review_int, x_dev_review_masks = id_aspect(dev, 0)\n",
        "\n",
        "x_dev_aspect_int = []\n",
        "x_dev_aspect_masks = []\n",
        "\n",
        "x_dev_aspect_int, x_dev_aspect_masks = id_aspect(dev, 1)\n",
        "\n",
        "#Train Data\n",
        "x_train_review_int = []\n",
        "x_train_review_masks = []\n",
        "\n",
        "x_train_review_int, x_train_review_masks = id_aspect(train, 0)\n",
        "\n",
        "x_train_aspect_int = []\n",
        "x_train_aspect_masks = []\n",
        "\n",
        "x_train_aspect_int, x_train_aspect_masks = id_aspect(train, 1)\n",
        "\n",
        "#Test Data\n",
        "x_test_review_int = []\n",
        "x_test_review_masks = []\n",
        "\n",
        "x_test_review_int, x_test_review_masks = id_aspect(test, 0)\n",
        "\n",
        "x_test_aspect_int = []\n",
        "x_test_aspect_masks = []\n",
        "\n",
        "x_test_aspect_int, x_test_aspect_masks = id_aspect(test, 1)\n",
        "\n",
        "\n",
        "\n",
        "# If use the previous tokenize function, you can get a print result like:\n",
        "assert len(x_train_aspect_int) == len(train)\n",
        "assert len(x_train_aspect_masks) == len(x_train_aspect_int)\n",
        "assert len(x_test_aspect_int) == len(test)\n",
        "assert len(x_test_aspect_masks) == len(x_test_aspect_int)\n",
        "\n",
        "print(\"x_dev_aspect_int[0]:\")\n",
        "print(x_dev_aspect_int[0])\n",
        "print(\"x_dev_aspect_masks[0]:\")\n",
        "print(x_dev_aspect_masks[0])\n",
        "print(\"x_dev_review_int[0]:\")\n",
        "print(x_dev_review_int[0])\n",
        "print(\"x_dev_review_masks[0]:\")\n",
        "print(x_dev_review_masks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IreFXgruZot"
      },
      "source": [
        "We one-hot encode the labels, using 4 (Binary:100) to represent \"positive\", 2 (Binary:010) for \"neutral\", and 1 (Binary:001) for \"negative\". Then we can convert the labels to numbers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.append(x_dev_review_int[0] , x_dev_aspect_int[0][1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzaTnSfboin2",
        "outputId": "139cff7c-7fc4-4dea-932b-27b03a90c6e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2044,  1037,  3232,  1997,  8974,  1010,  1996, 18726,\n",
              "        1011,  1011,  1045,  2066,  1996, 27940,  1013, 24792,  2621,\n",
              "        4897,  1998,  1996, 13675, 11514,  6508, 26852,  1011,  1011,\n",
              "        2175,  2091,  2307,  1012,   102,  8974,   102], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abIb7Fe5u3GQ",
        "outputId": "acd352d0-ee56-433d-f847-717ad203fa72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1]\n",
            "[1 0 0]\n",
            "[1 0 0]\n",
            "[0 1 0]\n",
            "[0 0 1]\n"
          ]
        }
      ],
      "source": [
        "def label2int(dataset):\n",
        "  y = []\n",
        "  for example in dataset:\n",
        "    if example[2].lower() == \"negative\":\n",
        "      y.append([0,0,1])\n",
        "    elif example[2].lower() == \"neutral\":\n",
        "      y.append([0,1,0])\n",
        "    else:\n",
        "      # assert example[2].lower() == \"positive\"\n",
        "      y.append([1,0,0])\n",
        "  return y\n",
        "  \n",
        "y_train = label2int(train)\n",
        "y_dev = label2int(dev)\n",
        "y_test = label2int(test)\n",
        "y_train = np.array(y_train)\n",
        "y_dev = np.array(y_dev)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train[1])\n",
        "print(y_train[2])\n",
        "print(y_train[3])\n",
        "print(y_train[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnnSuspvC5b"
      },
      "source": [
        "Now we have almost done the data preprocessing. Unlike the previous lab1-lab4, there are two x (review and aspect) to input the model. The easiest way is to combine the review and aspect into one sentence and then input it into the model. Thus we can use the previous model directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKOiVVXQu-_I",
        "outputId": "460959e0-5d07-45bd-9a14-f3a77dae9048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
            "\n",
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Please write your code to combine the tweet and topic into the following varibles\n",
        "# x_train_int\n",
        "# x_train_masks\n",
        "# x_dev_int\n",
        "# x_dev_masks\n",
        "# x_test_int\n",
        "# x_test_masks\n",
        "\n",
        "# Tips: \n",
        "# 1) We can use the special token <SEP> to concatenate the tweets and topics.\n",
        "# 2) After combine them, make sure they are paded.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combiner(review_int, aspect_int, review_masks, aspect_masks):\n",
        "  x_data_int = [np.append(review_int[i], aspect_int[i][1: ]) for i in range(len(review_int))]\n",
        "  x_data_masks = [np.append(review_masks[i], aspect_masks[i][1:])  for i in range(len(review_masks))]\n",
        "  x_data_int = keras.preprocessing.sequence.pad_sequences(x_data_int, maxlen = 128, padding = 'post', value = 0)\n",
        "  x_data_masks = keras.preprocessing.sequence.pad_sequences(x_data_masks, maxlen = 128, padding = 'post', value = 0)\n",
        "  return x_data_int, x_data_masks\n",
        "\n",
        "x_train_int, x_train_masks = combiner(x_train_review_int, x_train_aspect_int, x_train_review_masks, x_train_aspect_masks)\n",
        "x_dev_int, x_dev_masks = combiner(x_dev_review_int, x_dev_aspect_int, x_dev_review_masks, x_dev_aspect_masks)\n",
        "x_test_int, x_test_masks = combiner(x_test_review_int, x_test_aspect_int, x_test_review_masks, x_test_aspect_masks)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Don't forget the to use np.array function to wrap the ouput of pad_sequences function\n",
        "x_train_int_np = np.array(x_train_int)\n",
        "x_train_masks_np = np.array(x_train_masks)\n",
        "x_dev_int_np = np.array(x_dev_int)\n",
        "x_dev_masks_np = np.array(x_dev_masks)\n",
        "x_test_int_np = np.array(x_test_int)\n",
        "x_test_masks_np = np.array(x_test_masks)\n",
        "\n",
        "\n",
        "print(x_dev_int[0])\n",
        "print(x_dev_masks[0],'\\n')\n",
        "print(x_dev_int_np[0])\n",
        "print(x_dev_masks_np[0]) # senetnce + aspect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqvUGIwwGJqu"
      },
      "source": [
        "## Model 1: Prebuilt Sequence Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSxC41ln07im"
      },
      "source": [
        "The huggingface transformer package provides many prebuilt models. Now let us try a sequence classification model based on distillBERT. \n",
        "\n",
        "The models with BERT are much bigger than our previous models. To run it faster, we can use TPU here. The detailed guideline about using TPU can be found from https://www.tensorflow.org/guide/tpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gXFbb2cxBlw",
        "outputId": "86a40b45-c838-47d3-c2c4-1e58dcb400de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.9.156.2:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.9.156.2:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.156.2:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.156.2:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_59']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
        "import tensorflow as tf\n",
        "\n",
        "distil_bert = 'distilbert-base-uncased'\n",
        "\n",
        "config = DistilBertConfig(num_labels=3)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "def create_TFDistilBertForSequenceClassification():\n",
        "  transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n",
        "  input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "  input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
        "  X = transformer_model(input_ids, input_masks_ids)\n",
        "  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model on TPU:\n",
        "  with strategy.scope():\n",
        "    model = create_TFDistilBertForSequenceClassification()\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model = create_TFDistilBertForSequenceClassification()\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CPFj0CMx9mw",
        "outputId": "bc22e132-c25d-4ff9-88cd-58be0c641c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66955779   ['input_token[0][0]',            \n",
            " assification_2 (TFDistilBertFo  rOutput(loss=None,               'masked_token[0][0]']           \n",
            " rSequenceClassification)       logits=(None, 3),                                                 \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,955,779\n",
            "Trainable params: 66,955,779\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "id": "z-3bAqHlt1la"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQQH5lE_33Vn",
        "outputId": "6e4259e8-ec1f-456c-a6f1-39cc7a7388fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 109s 3s/step - loss: 0.8677 - accuracy: 0.4156 - val_loss: 0.5796 - val_accuracy: 0.4685\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.5800 - accuracy: 0.4954 - val_loss: 0.5351 - val_accuracy: 0.5488\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.5095 - accuracy: 0.6219 - val_loss: 0.4668 - val_accuracy: 0.6727\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.4152 - accuracy: 0.7312 - val_loss: 0.3903 - val_accuracy: 0.7725\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.3542 - accuracy: 0.7998 - val_loss: 0.3554 - val_accuracy: 0.7898\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.3442 - accuracy: 0.8084 - val_loss: 0.4112 - val_accuracy: 0.7853\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.3261 - accuracy: 0.8248 - val_loss: 0.4204 - val_accuracy: 0.7890\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 228ms/step - loss: 0.2928 - accuracy: 0.8462 - val_loss: 0.4774 - val_accuracy: 0.7920\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.2581 - accuracy: 0.8604 - val_loss: 0.4162 - val_accuracy: 0.8048\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.2457 - accuracy: 0.8781 - val_loss: 0.4551 - val_accuracy: 0.8063\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.2239 - accuracy: 0.8888 - val_loss: 0.7564 - val_accuracy: 0.8123\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1899 - accuracy: 0.9149 - val_loss: 0.7545 - val_accuracy: 0.8041\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1599 - accuracy: 0.9297 - val_loss: 0.7484 - val_accuracy: 0.8153\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.1400 - accuracy: 0.9401 - val_loss: 0.9401 - val_accuracy: 0.8153\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.1476 - accuracy: 0.9418 - val_loss: 0.8822 - val_accuracy: 0.8176\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1207 - accuracy: 0.9560 - val_loss: 1.1303 - val_accuracy: 0.8063\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1830 - accuracy: 0.9372 - val_loss: 0.9133 - val_accuracy: 0.7635\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 230ms/step - loss: 0.1656 - accuracy: 0.9347 - val_loss: 1.0313 - val_accuracy: 0.8041\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 228ms/step - loss: 0.1241 - accuracy: 0.9551 - val_loss: 0.9316 - val_accuracy: 0.8078\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.5018 - accuracy: 0.7323 - val_loss: 0.4854 - val_accuracy: 0.7095\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.3564 - accuracy: 0.8470 - val_loss: 0.6971 - val_accuracy: 0.7778\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.2300 - accuracy: 0.9006 - val_loss: 0.7297 - val_accuracy: 0.7935\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1618 - accuracy: 0.9316 - val_loss: 0.7712 - val_accuracy: 0.8101\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 230ms/step - loss: 0.1568 - accuracy: 0.9347 - val_loss: 0.7760 - val_accuracy: 0.8138\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1180 - accuracy: 0.9538 - val_loss: 0.9459 - val_accuracy: 0.8116\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.1030 - accuracy: 0.9625 - val_loss: 0.9458 - val_accuracy: 0.8063\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.0872 - accuracy: 0.9683 - val_loss: 0.9517 - val_accuracy: 0.8056\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.0736 - accuracy: 0.9737 - val_loss: 1.1053 - val_accuracy: 0.8131\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 228ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 1.1779 - val_accuracy: 0.8101\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1154 - accuracy: 0.9688 - val_loss: 1.1788 - val_accuracy: 0.7845\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQcytuBdaWVp",
        "outputId": "d4930b63-9607-48ca-b2e4-5901f8dc1ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 8s 103ms/step - loss: 1.0974 - accuracy: 0.7927\n",
            "[1.0974481105804443, 0.7926647067070007]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdZ4nl08vp9A"
      },
      "source": [
        "\n",
        "## Model 2: Neural bag of words using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gyCwXFj_R5w"
      },
      "source": [
        "We use model3-1 from lab4 to integrate BERT, using BERT instead of the previous static word embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DStlnRQRf-4v"
      },
      "outputs": [],
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTwmYDvNEyT"
      },
      "outputs": [],
      "source": [
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "\n",
        "def get_BERT_layer():\n",
        "  distil_bert = 'distilbert-base-uncased'\n",
        "  config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "  config.output_hidden_states = False\n",
        "  return TFDistilBertModel.from_pretrained(distil_bert, config = config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICS9rY8C7KH",
        "outputId": "e1aa6bd9-9854-4693-8471-8f34f6244596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.49.169.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.49.169.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.49.169.42:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.49.169.42:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_2 (TFDist  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
            " ilBertModel)                   ast_hidden_state=(N               'masked_token[0][0]']           \n",
            "                                one, 128, 768),                                                   \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_maske  (None, 768)         0           ['tf_distil_bert_model_2[0][0]'] \n",
            " d_2 (GlobalAveragePooling1DMas                                                                   \n",
            " ked)                                                                                             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 16)           12304       ['global_average_pooling1d_masked\n",
            "                                                                 _2[0][0]']                       \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 3)            51          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,375,235\n",
            "Trainable params: 66,375,235\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "hdepth=16\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "EMBED_SIZE=100\n",
        "\n",
        "\n",
        "def create_bag_of_words_BERT():\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32') \n",
        "\n",
        "  bert_embeddings = get_BERT_layer()\n",
        "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "\n",
        "  pooled_sent=GlobalAveragePooling1DMasked()(embedded_sent)\n",
        "  hidden_output=Dense(hdepth,input_shape=(MAX_SEQUENCE_LENGTH,EMBED_SIZE),activation='sigmoid',kernel_initializer='glorot_uniform')(pooled_sent) # Sigmoid\n",
        "  label=Dense(3,input_shape=(hdepth,),activation='softmax',kernel_initializer='glorot_uniform')(hidden_output)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model2 = create_bag_of_words_BERT()\n",
        "    optimizer2 = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model2 = create_bag_of_words_BERT()\n",
        "  model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary() \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0SbsCsxF1zi",
        "outputId": "092c2aa3-e29b-4e41-af1b-7341673b18fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 108s 2s/step - loss: 0.6284 - accuracy: 0.4555 - val_loss: 0.5914 - val_accuracy: 0.4767\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 217ms/step - loss: 0.5813 - accuracy: 0.4954 - val_loss: 0.5662 - val_accuracy: 0.5691\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.5445 - accuracy: 0.6175 - val_loss: 0.5265 - val_accuracy: 0.6697\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 216ms/step - loss: 0.5118 - accuracy: 0.6944 - val_loss: 0.4969 - val_accuracy: 0.7380\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 0.4775 - accuracy: 0.7650 - val_loss: 0.4770 - val_accuracy: 0.7755\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 0.4553 - accuracy: 0.8094 - val_loss: 0.4676 - val_accuracy: 0.7920\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.4401 - accuracy: 0.8419 - val_loss: 0.4626 - val_accuracy: 0.7965\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.4265 - accuracy: 0.8709 - val_loss: 0.4597 - val_accuracy: 0.8041\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 217ms/step - loss: 0.4150 - accuracy: 0.8909 - val_loss: 0.4608 - val_accuracy: 0.8108\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.4071 - accuracy: 0.9039 - val_loss: 0.4582 - val_accuracy: 0.8161\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 0.4000 - accuracy: 0.9161 - val_loss: 0.4608 - val_accuracy: 0.8153\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.3937 - accuracy: 0.9246 - val_loss: 0.4556 - val_accuracy: 0.8071\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.3857 - accuracy: 0.9389 - val_loss: 0.4540 - val_accuracy: 0.8168\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.3826 - accuracy: 0.9412 - val_loss: 0.4562 - val_accuracy: 0.8191\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.3771 - accuracy: 0.9492 - val_loss: 0.4523 - val_accuracy: 0.8138\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 217ms/step - loss: 0.3713 - accuracy: 0.9554 - val_loss: 0.4539 - val_accuracy: 0.8191\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 0.3687 - accuracy: 0.9582 - val_loss: 0.4503 - val_accuracy: 0.8146\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.3633 - accuracy: 0.9644 - val_loss: 0.4508 - val_accuracy: 0.8161\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 236ms/step - loss: 0.3617 - accuracy: 0.9643 - val_loss: 0.4516 - val_accuracy: 0.8131\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3591 - accuracy: 0.9659 - val_loss: 0.4460 - val_accuracy: 0.8243\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.3533 - accuracy: 0.9742 - val_loss: 0.4433 - val_accuracy: 0.8206\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.3523 - accuracy: 0.9719 - val_loss: 0.4474 - val_accuracy: 0.8221\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.3518 - accuracy: 0.9701 - val_loss: 0.4426 - val_accuracy: 0.8206\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.3481 - accuracy: 0.9741 - val_loss: 0.4390 - val_accuracy: 0.8236\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.3457 - accuracy: 0.9743 - val_loss: 0.4404 - val_accuracy: 0.8311\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 0.3430 - accuracy: 0.9765 - val_loss: 0.4386 - val_accuracy: 0.8221\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 0.3400 - accuracy: 0.9798 - val_loss: 0.4371 - val_accuracy: 0.8213\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.3388 - accuracy: 0.9785 - val_loss: 0.4386 - val_accuracy: 0.8273\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 0.3374 - accuracy: 0.9782 - val_loss: 0.4311 - val_accuracy: 0.8348\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 0.3347 - accuracy: 0.9794 - val_loss: 0.4328 - val_accuracy: 0.8273\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model2.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs0_vvG6UQtv",
        "outputId": "8df73bbb-7cb4-4812-b06e-a17d3c23b148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 8s 106ms/step - loss: 0.4367 - accuracy: 0.8211\n",
            "[0.4367244243621826, 0.821107804775238]\n"
          ]
        }
      ],
      "source": [
        "results = model2.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awOphcCnhEwv"
      },
      "source": [
        "## Model 3: CNN or LSTM with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5codSzohQ_9"
      },
      "source": [
        "Please follow the same methods as model2 to construct a CNN or LSTM model on top of BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "72abbe662afb4d4b940ba597c45a7be8",
            "cabddf42f31e4824823787eb3a382857",
            "1e297e5308a946e386d97eb36ad5f915",
            "81bb3189b8fd47b3a68acf5abf80ff6f",
            "c83a41840f834cac829c8cfa2266aab3",
            "3b9b24ff606e4543a2cc923ba952829a",
            "ae5b27fe767d45f390d4111642a5d011",
            "9b760994d8cc458f9c32a4a36e069f40",
            "a61e8c978f7b4349b7844df7f53c0e4e",
            "d0783c18b8304ef8b4df4c5f144e8db2",
            "2dbc1bd1ed644abb881a1e790edfd184"
          ]
        },
        "id": "JMiiWhW4hPRA",
        "outputId": "78ba8644-9774-497b-b576-105ef2961aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.93.52.178:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.93.52.178:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72abbe662afb4d4b940ba597c45a7be8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Model3_LSTM\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
            " BertModel)                     ast_hidden_state=(N               'masked_token[0][0]']           \n",
            "                                one, 128, 768),                                                   \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " LSTM (LSTM)                    (None, 100)          347600      ['tf_distil_bert_model[0][0]']   \n",
            "                                                                                                  \n",
            " Output (Dense)                 (None, 3)            303         ['LSTM[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,710,783\n",
            "Trainable params: 66,710,783\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# your code goes here\n",
        "\n",
        "\n",
        "model3.summary() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9HmJNzNpIEM",
        "outputId": "a76d47bc-6156-4371-9ce4-ada6274a7ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 111s 3s/step - loss: 0.5931 - accuracy: 0.4763 - val_loss: 0.5041 - val_accuracy: 0.6306\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 7s 298ms/step - loss: 0.4713 - accuracy: 0.6479 - val_loss: 0.4107 - val_accuracy: 0.7155\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.3686 - accuracy: 0.7487 - val_loss: 0.3271 - val_accuracy: 0.7883\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.2918 - accuracy: 0.8146 - val_loss: 0.3042 - val_accuracy: 0.8131\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 7s 298ms/step - loss: 0.2356 - accuracy: 0.8580 - val_loss: 0.2930 - val_accuracy: 0.8206\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.1962 - accuracy: 0.8881 - val_loss: 0.3201 - val_accuracy: 0.8146\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 297ms/step - loss: 0.1663 - accuracy: 0.9070 - val_loss: 0.3232 - val_accuracy: 0.8206\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 7s 310ms/step - loss: 0.1374 - accuracy: 0.9263 - val_loss: 0.3301 - val_accuracy: 0.8206\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 295ms/step - loss: 0.1168 - accuracy: 0.9400 - val_loss: 0.3451 - val_accuracy: 0.8161\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 7s 300ms/step - loss: 0.0932 - accuracy: 0.9542 - val_loss: 0.3716 - val_accuracy: 0.8236\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 289ms/step - loss: 0.0798 - accuracy: 0.9616 - val_loss: 0.3695 - val_accuracy: 0.8243\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.0715 - accuracy: 0.9661 - val_loss: 0.3702 - val_accuracy: 0.8281\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0657 - accuracy: 0.9715 - val_loss: 0.4048 - val_accuracy: 0.8191\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 290ms/step - loss: 0.0551 - accuracy: 0.9746 - val_loss: 0.4136 - val_accuracy: 0.8236\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.0523 - accuracy: 0.9765 - val_loss: 0.4219 - val_accuracy: 0.8146\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 296ms/step - loss: 0.0483 - accuracy: 0.9793 - val_loss: 0.4314 - val_accuracy: 0.8303\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 294ms/step - loss: 0.0395 - accuracy: 0.9842 - val_loss: 0.4370 - val_accuracy: 0.8191\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0378 - accuracy: 0.9843 - val_loss: 0.4530 - val_accuracy: 0.8161\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 294ms/step - loss: 0.0341 - accuracy: 0.9860 - val_loss: 0.4587 - val_accuracy: 0.8176\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.0337 - accuracy: 0.9864 - val_loss: 0.4572 - val_accuracy: 0.8191\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 294ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.4605 - val_accuracy: 0.8191\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 295ms/step - loss: 0.0307 - accuracy: 0.9883 - val_loss: 0.4671 - val_accuracy: 0.8168\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 7s 299ms/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.4638 - val_accuracy: 0.8138\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 7s 298ms/step - loss: 0.0254 - accuracy: 0.9897 - val_loss: 0.4785 - val_accuracy: 0.8123\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 290ms/step - loss: 0.0274 - accuracy: 0.9890 - val_loss: 0.4717 - val_accuracy: 0.8198\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 290ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.4776 - val_accuracy: 0.8161\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.5223 - val_accuracy: 0.8063\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.5157 - val_accuracy: 0.8101\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 7s 300ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.4895 - val_accuracy: 0.8258\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 291ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.5054 - val_accuracy: 0.8198\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model3.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7TXLjQhpY--",
        "outputId": "300d00fb-2a93-41bb-cf91-fc9e4e4f3320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 10s 112ms/step - loss: 0.4750 - accuracy: 0.8293\n",
            "[0.4750474989414215, 0.8293413519859314]\n"
          ]
        }
      ],
      "source": [
        "results = model3.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Aspect-Based Sentiment Analysis with BERT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e297e5308a946e386d97eb36ad5f915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b760994d8cc458f9c32a4a36e069f40",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61e8c978f7b4349b7844df7f53c0e4e",
            "value": 363423424
          }
        },
        "2dbc1bd1ed644abb881a1e790edfd184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b9b24ff606e4543a2cc923ba952829a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72abbe662afb4d4b940ba597c45a7be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cabddf42f31e4824823787eb3a382857",
              "IPY_MODEL_1e297e5308a946e386d97eb36ad5f915",
              "IPY_MODEL_81bb3189b8fd47b3a68acf5abf80ff6f"
            ],
            "layout": "IPY_MODEL_c83a41840f834cac829c8cfa2266aab3"
          }
        },
        "81bb3189b8fd47b3a68acf5abf80ff6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0783c18b8304ef8b4df4c5f144e8db2",
            "placeholder": "​",
            "style": "IPY_MODEL_2dbc1bd1ed644abb881a1e790edfd184",
            "value": " 347M/347M [00:11&lt;00:00, 33.1MB/s]"
          }
        },
        "9b760994d8cc458f9c32a4a36e069f40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61e8c978f7b4349b7844df7f53c0e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae5b27fe767d45f390d4111642a5d011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83a41840f834cac829c8cfa2266aab3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabddf42f31e4824823787eb3a382857": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9b24ff606e4543a2cc923ba952829a",
            "placeholder": "​",
            "style": "IPY_MODEL_ae5b27fe767d45f390d4111642a5d011",
            "value": "Downloading: 100%"
          }
        },
        "d0783c18b8304ef8b4df4c5f144e8db2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603b444594044c13bcd95e4326932916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a45d989bad384e6bb09d3fd648485481",
              "IPY_MODEL_8996286e91b446acba5d31753a2121e1",
              "IPY_MODEL_020814c33aa34187ac9f46631204b3ad"
            ],
            "layout": "IPY_MODEL_e43c6551c5264decb678dec78d47ca89"
          }
        },
        "a45d989bad384e6bb09d3fd648485481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44e3ca7ef4f40699035d53c2230650b",
            "placeholder": "​",
            "style": "IPY_MODEL_b8ec4135f891402d9e855025de7fd139",
            "value": "Downloading: 100%"
          }
        },
        "8996286e91b446acba5d31753a2121e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fcf93d4a154c2faac2e61d974bcd8b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e88d50bcdd44b9948dbf2b26fd5619",
            "value": 231508
          }
        },
        "020814c33aa34187ac9f46631204b3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34751423926b4d5a92a987fb7b66d825",
            "placeholder": "​",
            "style": "IPY_MODEL_076763a9cf6f437faa1eed7fae368ef2",
            "value": " 226k/226k [00:00&lt;00:00, 804kB/s]"
          }
        },
        "e43c6551c5264decb678dec78d47ca89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e44e3ca7ef4f40699035d53c2230650b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ec4135f891402d9e855025de7fd139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8fcf93d4a154c2faac2e61d974bcd8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e88d50bcdd44b9948dbf2b26fd5619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34751423926b4d5a92a987fb7b66d825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076763a9cf6f437faa1eed7fae368ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63d4af1040644f8ab868bc4e1ebb824b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d599a08bba348ffa3713281329c5ecc",
              "IPY_MODEL_eab4d125e4d645cc8794fef7d9c729df",
              "IPY_MODEL_e679624f746143458f9aa8cd8fa9ae8c"
            ],
            "layout": "IPY_MODEL_5d3b0b66524c4c11a6df09ea04839d6a"
          }
        },
        "5d599a08bba348ffa3713281329c5ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b7a50632b74a7e8de6f46adb99fc54",
            "placeholder": "​",
            "style": "IPY_MODEL_c649cec29f5c466895fda131bcfe2066",
            "value": "Downloading: 100%"
          }
        },
        "eab4d125e4d645cc8794fef7d9c729df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2897a4b6f0e14ce491a8eeba3aec35d9",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c6499375ece40b4b242cf29721338b8",
            "value": 28
          }
        },
        "e679624f746143458f9aa8cd8fa9ae8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381f195ac3d14e3da41361f694ce6576",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7a19a3230f4b039c7e60aad832d24d",
            "value": " 28.0/28.0 [00:00&lt;00:00, 484B/s]"
          }
        },
        "5d3b0b66524c4c11a6df09ea04839d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b7a50632b74a7e8de6f46adb99fc54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c649cec29f5c466895fda131bcfe2066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2897a4b6f0e14ce491a8eeba3aec35d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6499375ece40b4b242cf29721338b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381f195ac3d14e3da41361f694ce6576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7a19a3230f4b039c7e60aad832d24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a945c9b3275464383694131671471cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_626c275f65fc473d9c39972fb75f8430",
              "IPY_MODEL_b5fdbe67f0954c15acb312306da61f26",
              "IPY_MODEL_253bdcf2debc46eea9b8c339e3a06159"
            ],
            "layout": "IPY_MODEL_cb270f10aa204daeb1846861ac7ae97e"
          }
        },
        "626c275f65fc473d9c39972fb75f8430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f436b1ec37cf47fcaa99a3aad033a003",
            "placeholder": "​",
            "style": "IPY_MODEL_540df8063f0b431da5558a3772fa8066",
            "value": "Downloading: 100%"
          }
        },
        "b5fdbe67f0954c15acb312306da61f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9ddcf3406147b7a2d69e7327f0e461",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f194fd3087e4ac5bbf0333de3497e46",
            "value": 483
          }
        },
        "253bdcf2debc46eea9b8c339e3a06159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c2e5d4f6a8849068636a367a481d84b",
            "placeholder": "​",
            "style": "IPY_MODEL_19bae60aec6d4189b9c5c01787d83b21",
            "value": " 483/483 [00:00&lt;00:00, 6.86kB/s]"
          }
        },
        "cb270f10aa204daeb1846861ac7ae97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f436b1ec37cf47fcaa99a3aad033a003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540df8063f0b431da5558a3772fa8066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d9ddcf3406147b7a2d69e7327f0e461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f194fd3087e4ac5bbf0333de3497e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c2e5d4f6a8849068636a367a481d84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bae60aec6d4189b9c5c01787d83b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}